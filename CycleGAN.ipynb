{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import imageio\n",
    "from skimage.transform import resize\n",
    "from glob import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, dataset_name, img_res=(128, 128)):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.img_res = img_res\n",
    "        \n",
    "        \n",
    "    def load_data(self, domain, batch_size=1, is_testing=False):\n",
    "        data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n",
    "        path = glob('./datasets/%s/%s/*' % (self.dataset_name, data_type))\n",
    "        \n",
    "        batch_images = np.random.choice(path, size=batch_size)\n",
    "        \n",
    "        imgs = []\n",
    "        for img_path in batch_images:\n",
    "            img = self.imread(img_path)\n",
    "            if not is_testing:\n",
    "                img = resize(img, self.img_res)\n",
    "                \n",
    "                if np.random.random() > 0.5:\n",
    "                    img = np.fliplr(img)\n",
    "            \n",
    "            else:\n",
    "                img = resize(img, self.img_res)\n",
    "            imgs.append(img)\n",
    "        \n",
    "        imgs = np.array(imgs) / 127.5 - 1.\n",
    "        \n",
    "        return imgs\n",
    "    \n",
    "    \n",
    "    def load_batch(self, batch_size=1, is_testing=False):\n",
    "        data_type = \"train\" if not is_testing else \"val\"\n",
    "        path_A = glob('./datasets/%s/%sA/*' % (self.dataset_name, data_type))\n",
    "        path_B = glob('./datasets/%s/%sB/*' % (self.dataset_name, data_type))\n",
    "        \n",
    "        self.n_batches = int(min(len(path_A), len(path_B)) / batch_size)\n",
    "        total_samples = self.n_batches * batch_size\n",
    "        \n",
    "        # Sample n_batches* batch_size from each path list so that model sees all\n",
    "        \n",
    "        # samples from both domains\n",
    "        path_A = np.random.choice(path_A, total_samples, replace=False)\n",
    "        path_B = np.random.choice(path_B, total_samples, replace=False)\n",
    "        \n",
    "        for i in range(self.n_batches-1):\n",
    "            batch_A = path_A[i * batch_size:(i+1)*batch_size]\n",
    "            batch_B = path_B[i * batch_size:(i+1)*batch_size]\n",
    "            imgs_A, imgs_B = [], []\n",
    "            for img_A, img_B in zip(batch_A, batch_B):\n",
    "                img_A = self.imread(img_A)\n",
    "                img_B = self.imread(img_B)\n",
    "                \n",
    "                img_A = resize(img_A, self.img_res)\n",
    "                img_B = resize(img_B, self.img_res)\n",
    "                \n",
    "                if not is_testing and np.random.random() > 0.5:\n",
    "                    img_A = np.fliplr(img_A)\n",
    "                    img_B = np.fliplr(img_B)\n",
    "                    \n",
    "                imgs_A.append(img_A)\n",
    "                imgs_B.append(img_B)\n",
    "                \n",
    "            imgs_A = np.array(imgs_A) / 127.5 - 1\n",
    "            imgs_B = np.array(imgs_B) / 127.5 - 1\n",
    "            \n",
    "            yield imgs_A, imgs_B\n",
    "            \n",
    "            \n",
    "    def imread(self, path):\n",
    "        return imageio.imread(path, pilmode=\"RGB\").astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 9-1 패키지 임포트\n",
    "from __future__ import print_function, division\n",
    "import scipy\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN():\n",
    "    def __init__(self):\n",
    "        # 입력 크기\n",
    "        self.img_rows = 128\n",
    "        self.img_cols = 128\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        # 데이터 로더 설정\n",
    "        self.dataset_name = 'apple2orange'\n",
    "        # DataLoader 객체를 사용해 전처리된 데이터 임포트합니다.\n",
    "        self.data_loader = DataLoader(dataset_name=self.dataset_name,\n",
    "                                      img_res=(self.img_rows, self.img_cols))\n",
    "\n",
    "        # D(PatchGAN)의 출력 크기를 계산합니다.\n",
    "        patch = int(self.img_rows / 2**4)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "\n",
    "        # G와 D의 첫 번째 층에 있는 필터의 개수\n",
    "        self.gf = 32\n",
    "        self.df = 64\n",
    "\n",
    "        # 손실 가중치\n",
    "        self.lambda_cycle = 10.0                    # 사이클-일관성 손실\n",
    "        self.lambda_id = 0.9 * self.lambda_cycle    # 동일성 손실\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "        \n",
    "        # 판별자를 만들고 컴파일합니다.\n",
    "        self.d_A = self.build_discriminator()\n",
    "        self.d_B = self.build_discriminator()\n",
    "        self.d_A.compile(loss='mse',\n",
    "                         optimizer=optimizer,\n",
    "                         metrics=['accuracy'])\n",
    "        self.d_B.compile(loss='mse',\n",
    "                         optimizer=optimizer,\n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "        #-------------------------\n",
    "        # 생성자의 계산 그래프를 만듭니다.\n",
    "        #-------------------------\n",
    "\n",
    "        # 생성자를 만듭니다.\n",
    "        self.g_AB = self.build_generator()\n",
    "        self.g_BA = self.build_generator()\n",
    "\n",
    "        # 두 도메인의 입력 이미지\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "\n",
    "        # 이미지를 다른 도메인으로 변환합니다.\n",
    "        fake_B = self.g_AB(img_A)\n",
    "        fake_A = self.g_BA(img_B)\n",
    "        # 원본 도메인으로 이미지를 다시 변환합니다.\n",
    "        reconstr_A = self.g_BA(fake_B)\n",
    "        reconstr_B = self.g_AB(fake_A)\n",
    "        # 동일한 이미지 매핑\n",
    "        img_A_id = self.g_BA(img_A)\n",
    "        img_B_id = self.g_AB(img_B)\n",
    "\n",
    "        # 연결 모델에서는 생성자만 훈련합니다.\n",
    "        self.d_A.trainable = False\n",
    "        self.d_B.trainable = False\n",
    "\n",
    "        # 판별자가 변환된 이미지를 검증합니다.\n",
    "        valid_A = self.d_A(fake_A)\n",
    "        valid_B = self.d_B(fake_B)\n",
    "\n",
    "        # 연결 모델은 판별자를 속이기 위한 생성자를 훈련합니다.\n",
    "        self.combined = Model(inputs=[img_A, img_B],\n",
    "                              outputs=[valid_A, valid_B,\n",
    "                                       reconstr_A, reconstr_B,\n",
    "                                       img_A_id, img_B_id])\n",
    "        self.combined.compile(loss=['mse', 'mse',\n",
    "                                    'mae', 'mae',\n",
    "                                    'mae', 'mae'],\n",
    "                              loss_weights=[1, 1,\n",
    "                                            self.lambda_cycle, self.lambda_cycle,\n",
    "                                            self.lambda_id, self.lambda_id],\n",
    "                              optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN(CycleGAN):\n",
    "    @staticmethod\n",
    "    def conv2d(layer_input, filters, f_size=4, normalization=True):\n",
    "        \"다운샘플링하는 동안 사용되는 층\"\n",
    "        d = Conv2D(filters, kernel_size=f_size,\n",
    "                   strides=2, padding='same')(layer_input)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        if normalization:\n",
    "            d = InstanceNormalization()(d)\n",
    "        return d\n",
    "      \n",
    "        \n",
    "    @staticmethod\n",
    "    def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "        \"업샘플링하는 동안 사용되는 층\"\n",
    "        u = UpSampling2D(size=2)(layer_input)\n",
    "        u = Conv2D(filters, kernel_size=f_size, strides=1,\n",
    "                    padding='same', activation='relu')(u)\n",
    "        if dropout_rate:\n",
    "            u = Dropout(dropout_rate)(u)\n",
    "        u = InstanceNormalization()(u)\n",
    "        u = Concatenate()([u, skip_input])\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN(CycleGAN):\n",
    "    def build_generator(self):\n",
    "        \"\"\"U-Net 생성자\"\"\"\n",
    "        # 이미지 입력\n",
    "        d0 = Input(shape=self.img_shape)\n",
    "\n",
    "        # 다운샘플링\n",
    "        d1 = self.conv2d(d0, self.gf)\n",
    "        d2 = self.conv2d(d1, self.gf * 2)\n",
    "        d3 = self.conv2d(d2, self.gf * 4)\n",
    "        d4 = self.conv2d(d3, self.gf * 8)\n",
    "\n",
    "        # 업샘플링\n",
    "        u1 = self.deconv2d(d4, d3, self.gf * 4)\n",
    "        u2 = self.deconv2d(u1, d2, self.gf * 2)\n",
    "        u3 = self.deconv2d(u2, d1, self.gf)\n",
    "\n",
    "        u4 = UpSampling2D(size=2)(u3)\n",
    "        output_img = Conv2D(self.channels, kernel_size=4,\n",
    "                            strides=1, padding='same', activation='tanh')(u4)\n",
    "\n",
    "        return Model(d0, output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN(CycleGAN):\n",
    "    def build_discriminator(self):\n",
    "        img = Input(shape=self.img_shape)\n",
    "        \n",
    "        d1 = self.conv2d(img, self.df, normalization=False)\n",
    "        d2 = self.conv2d(d1, self.df * 2)\n",
    "        d3 = self.conv2d(d2, self.df * 4)\n",
    "        d4 = self.conv2d(d3, self.df * 8)\n",
    "\n",
    "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
    "\n",
    "        return Model(img, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN(CycleGAN):\n",
    "      def sample_images(self, epoch, batch_i):\n",
    "        r, c = 2, 3\n",
    "\n",
    "        imgs_A = self.data_loader.load_data(domain=\"A\", batch_size=1, is_testing=True)\n",
    "        imgs_B = self.data_loader.load_data(domain=\"B\", batch_size=1, is_testing=True)\n",
    "        \n",
    "        # 이미지를 다른 도메인으로 변환합니다.\n",
    "        fake_B = self.g_AB.predict(imgs_A)\n",
    "        fake_A = self.g_BA.predict(imgs_B)\n",
    "        # 원본 도메인으로 되돌립니다.\n",
    "        reconstr_A = self.g_BA.predict(fake_B)\n",
    "        reconstr_B = self.g_AB.predict(fake_A)\n",
    "\n",
    "        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n",
    "\n",
    "        # 이미지를 0 - 1 사이로 스케일을 바꿉니다.\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        titles = ['Original', 'Translated', 'Reconstructed']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt])\n",
    "                axs[i, j].set_title(titles[j])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/%s/%d_%d.png\" % (self.dataset_name, epoch, batch_i))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN(CycleGAN):\n",
    "      def train(self, epochs, batch_size=1, sample_interval=50):\n",
    "        # 적대 손실에 대한 정답\n",
    "        valid = np.ones((batch_size,) + self.disc_patch)\n",
    "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size)):\n",
    "\n",
    "                # 이미지를 상대 도메인으로 변환합니다.\n",
    "                fake_B = self.g_AB.predict(imgs_A)\n",
    "                fake_A = self.g_BA.predict(imgs_B)\n",
    "\n",
    "                # 판별자를 훈련합니다. (원본 이미지 = real / 변환된 이미지 = fake)\n",
    "                dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n",
    "                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n",
    "                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
    "\n",
    "                dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n",
    "                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n",
    "                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
    "\n",
    "                # 판별자 전체 손실\n",
    "                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
    "\n",
    "                # 생성자를 훈련합니다.\n",
    "                g_loss = self.combined.train_on_batch([imgs_A, imgs_B],\n",
    "                                                      [valid, valid,\n",
    "                                                       imgs_A, imgs_B,\n",
    "                                                       imgs_A, imgs_B])\n",
    "                # save_interval 마다 생성된 이미지 샘플을 저장합니다.\n",
    "                if batch_i % sample_interval == 0:\n",
    "                    self.sample_images(epoch, batch_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_gan = CycleGAN()\n",
    "cycle_gan.train(epochs=100, batch_size=64, sample_interval=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.1.0-keras2.3.1-py3.6-cuda10.1",
   "language": "python",
   "name": "tf2.1.0-keras2.3.1-py3.6-cuda10.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
