{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 9-1 패키지 임포트\n",
    "from __future__ import print_function, division\n",
    "import scipy\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN():\n",
    "    def __init__(self):\n",
    "        # 입력 크기\n",
    "        self.img_rows = 256\n",
    "        self.img_cols = 256\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        # 데이터 로더 설정\n",
    "        self.dataset_name = \"vangogh2photo\" # choice dataset! [\"vangogh2photo\", \"monet2photo\", \"cezanne2photo\", \"ukiyoe2photo\"]\n",
    "        # DataLoadear 객체를 사용해 전처리된 데이터 임포트합니다.\n",
    "        self.data_loader = DataLoader(dataset_name=self.dataset_name,\n",
    "                                      img_res=(self.img_rows, self.img_cols))\n",
    "\n",
    "        # D(PatchGAN)의 출력 크기를 계산합니다.\n",
    "        patch = int(self.img_rows / 2**7)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "\n",
    "        # G와 D의 첫 번째 층에 있는 필터의 개수\n",
    "        self.gf = 32\n",
    "        self.df = 64 \n",
    "\n",
    "        # 손실 가중치\n",
    "        self.lambda_cycle = 10.0                    # 사이클-일관성 손실\n",
    "        self.lambda_id = 0.85 * self.lambda_cycle    # 동일성 손실\n",
    "    \n",
    "        self.optimizer_lr = 0.00015\n",
    "        self.optimizer = Adam(self.optimizer_lr, 0.5)\n",
    "        \n",
    "        # 판별자를 만들고 컴파일합니다.\n",
    "        self.d_A = self.build_discriminator()\n",
    "        self.d_B = self.build_discriminator()\n",
    "        self.d_A.compile(loss='mse',\n",
    "                         optimizer=self.optimizer,\n",
    "                         metrics=['accuracy'])\n",
    "        self.d_B.compile(loss='mse',\n",
    "                         optimizer=self.optimizer,\n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "        #-------------------------\n",
    "        # 생성자의 계산 그래프를 만듭니다.\n",
    "        #-------------------------\n",
    "\n",
    "        # 생성자를 만듭니다.\n",
    "        self.g_AB = self.build_generator()\n",
    "        self.g_BA = self.build_generator()\n",
    "\n",
    "        # 두 도메인의 입력 이미지\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "\n",
    "        # 이미지를 다른 도메인으로 변환합니다.\n",
    "        fake_B = self.g_AB(img_A)\n",
    "        fake_A = self.g_BA(img_B)\n",
    "        # 원본 도메인으로 이미지를 다시 변환합니다.\n",
    "        reconstr_A = self.g_BA(fake_B)\n",
    "        reconstr_B = self.g_AB(fake_A)\n",
    "        # 동일한 이미지 매핑\n",
    "        img_A_id = self.g_BA(img_A)\n",
    "        img_B_id = self.g_AB(img_B)\n",
    "\n",
    "        # 연결 모델에서는 생성자만 훈련합니다.\n",
    "        self.d_A.trainable = False\n",
    "        self.d_B.trainable = False\n",
    "\n",
    "        # 판별자가 변환된 이미지를 검증합니다.\n",
    "        valid_A = self.d_A(fake_A)\n",
    "        valid_B = self.d_B(fake_B)\n",
    "\n",
    "        # 연결 모델은 판별자를 속이기 위한 생성자를 훈련합니다.\n",
    "        self.combined = Model(inputs=[img_A, img_B],\n",
    "                              outputs=[valid_A, valid_B,\n",
    "                                       reconstr_A, reconstr_B,\n",
    "                                       img_A_id, img_B_id])\n",
    "        self.combined.compile(loss=['mse', 'mse',\n",
    "                                    'mae', 'mae',\n",
    "                                    'mae', 'mae'],\n",
    "                              loss_weights=[1, 1,\n",
    "                                            self.lambda_cycle, self.lambda_cycle,\n",
    "                                            self.lambda_id, self.lambda_id],\n",
    "                              optimizer=self.optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN(CycleGAN):\n",
    "    @staticmethod\n",
    "    def conv2d(layer_input, filters, f_size=4, normalization=True):\n",
    "        \"다운샘플링하는 동안 사용되는 층\"\n",
    "        d = Conv2D(filters, kernel_size=f_size,\n",
    "                   strides=2, padding='same')(layer_input)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        if normalization:\n",
    "            d = InstanceNormalization()(d)\n",
    "        return d\n",
    "      \n",
    "        \n",
    "    @staticmethod\n",
    "    def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "        \"업샘플링하는 동안 사용되는 층\"\n",
    "        u = UpSampling2D(size=2)(layer_input)\n",
    "        u = Conv2D(filters, kernel_size=f_size, strides=1,\n",
    "                    padding='same', activation='relu')(u)\n",
    "        if dropout_rate:\n",
    "            u = Dropout(dropout_rate)(u)\n",
    "        u = InstanceNormalization()(u)\n",
    "        u = Concatenate()([u, skip_input])\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN(CycleGAN):\n",
    "    def build_generator(self):\n",
    "        \"\"\"U-Net 생성자\"\"\"\n",
    "        # 이미지 입력\n",
    "        d0 = Input(shape=self.img_shape)\n",
    "\n",
    "        # 다운샘플링\n",
    "        d1 = self.conv2d(d0, self.gf)\n",
    "        d2 = self.conv2d(d1, self.gf * 2)\n",
    "        d3 = self.conv2d(d2, self.gf * 4)\n",
    "        d4 = self.conv2d(d3, self.gf * 8)\n",
    "        \n",
    "        d5 = self.conv2d(d4, self.gf * 16)\n",
    "        d6 = self.conv2d(d5, self.gf * 32)\n",
    "        d7 = self.conv2d(d6, self.gf * 64)\n",
    "\n",
    "        # 업샘플링\n",
    "        u1 = self.deconv2d(d7, d6, self.gf * 32)\n",
    "        u2 = self.deconv2d(u1, d5, self.gf * 16)\n",
    "        u3 = self.deconv2d(u2, d4, self.gf * 8)\n",
    "        u4 = self.deconv2d(u3, d3, self.gf * 4)\n",
    "        u5 = self.deconv2d(u4, d2, self.gf * 2)\n",
    "        u6 = self.deconv2d(u5, d1, self.gf)\n",
    "        \n",
    "        u7 = UpSampling2D(size=2)(u6)\n",
    "        output_img = Conv2D(self.channels, kernel_size=4,\n",
    "                            strides=1, padding='same', activation='tanh')(u7)\n",
    "\n",
    "        return Model(d0, output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN(CycleGAN):\n",
    "    def build_discriminator(self):\n",
    "        img = Input(shape=self.img_shape)\n",
    "        \n",
    "        d1 = self.conv2d(img, self.df, normalization=False)\n",
    "        d2 = self.conv2d(d1, self.df * 2)\n",
    "        d3 = self.conv2d(d2, self.df * 4)\n",
    "        d4 = self.conv2d(d3, self.df * 8)\n",
    "        d5 = self.conv2d(d4, self.df * 16)\n",
    "        d6 = self.conv2d(d5, self.df * 32)\n",
    "        d7 = self.conv2d(d6, self.df * 64)\n",
    "\n",
    "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d7)\n",
    "\n",
    "        return Model(img, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN(CycleGAN):\n",
    "      def sample_images(self, epoch, batch_i):\n",
    "        r, c = 2, 3\n",
    "\n",
    "        imgs_A = self.data_loader.load_data(domain=\"A\", batch_size=1, is_testing=True)\n",
    "        imgs_B = self.data_loader.load_data(domain=\"B\", batch_size=1, is_testing=True)\n",
    "        \n",
    "        # 이미지를 다른 도메인으로 변환합니다.\n",
    "        fake_B = self.g_AB.predict(imgs_A)\n",
    "        fake_A = self.g_BA.predict(imgs_B)\n",
    "        # 원본 도메인으로 되돌립니다.\n",
    "        reconstr_A = self.g_BA.predict(fake_B)\n",
    "        reconstr_B = self.g_AB.predict(fake_A)\n",
    "\n",
    "        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n",
    "\n",
    "        # 이미지를 0 - 1 사이로 스케일을 바꿉니다.\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        titles = ['Original', 'Translated', 'Reconstructed']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt])\n",
    "                axs[i, j].set_title(titles[j])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        #fig.savefig(\"images/%s/%d_%d.png\" % (self.dataset_name, epoch, batch_i))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN(CycleGAN):\n",
    "      def train(self, epochs, batch_size=1, sample_interval=50, verbose=1):\n",
    "        # 적대 손실에 대한 정답\n",
    "        valid = np.ones((batch_size,) + self.disc_patch)\n",
    "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "\n",
    "        # 100번 이상 실행시 lr 점진적 감소\n",
    "        if epochs > 100:\n",
    "            dec_rate = self.optimizer_lr / (epochs - 100) # 0.0002 / 100\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            if (epoch + 1) % verbose == 0:\n",
    "                print(\"[\" + \"=\" * int((epoch+1)/epochs * 100) + \">\" +  \"-\" * (100 - int((epoch+1)/epochs * 100))  + \"] \" + str(round(((epoch+1)/epochs * 100), 3)) + \"%\")\n",
    "            \n",
    "            if epoch >= 100:\n",
    "                self.optimizer_lr -= dec_rate\n",
    "                self.optimizer = Adam(self.optimizer_lr, 0.5)\n",
    "                \n",
    "            for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size)):\n",
    "\n",
    "                # 이미지를 상대 도메인으로 변환합니다.\n",
    "                fake_B = self.g_AB.predict(imgs_A)\n",
    "                fake_A = self.g_BA.predict(imgs_B)\n",
    "\n",
    "                # 판별자를 훈련합니다. (원본 이미지 = real / 변환된 이미지 = fake)\n",
    "                dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n",
    "                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n",
    "                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
    "\n",
    "                dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n",
    "                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n",
    "                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
    "\n",
    "                # 판별자 전체 손실\n",
    "                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
    "\n",
    "                # 생성자를 훈련합니다.\n",
    "                g_loss = self.combined.train_on_batch([imgs_A, imgs_B],\n",
    "                                                      [valid, valid,\n",
    "                                                       imgs_A, imgs_B,\n",
    "                                                       imgs_A, imgs_B])\n",
    "                # save_interval 마다 생성된 이미지 샘플을 저장합니다.\n",
    "                if batch_i % sample_interval == 0:\n",
    "                    self.sample_images(epoch, batch_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_gan = CycleGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_gan.train(epochs=100, batch_size=16, sample_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data_loader = DataLoader(dataset_name=\"school\",\n",
    "                                      img_res=(1024, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = school_data_loader.load_data(domain=\"B\", batch_size=5, is_testing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_gan.g_BA.save(\"photo2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_A = cycle_gan.g_BA.predict(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in fake_A:\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.1.0-keras2.3.1-py3.6-cuda10.1",
   "language": "python",
   "name": "tf2.1.0-keras2.3.1-py3.6-cuda10.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
